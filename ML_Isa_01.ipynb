{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "RMSE (Train), RMSE (Test) and MAE (Test)"
      ],
      "metadata": {
        "id": "F7nZeFnkUmS1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dnfn1Q6P3TL",
        "outputId": "731e9ae1-7379-4316-b0b1-2df0e56f0eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Comparison:\n",
            "\n",
            "               Model  RMSE (Train)   RMSE (Test)    MAE (Test)\n",
            "0  Linear Regression  68433.937367  70060.521845  50670.738241\n",
            "1   Ridge Regression  68433.944757  70057.416870  50668.122931\n",
            "2      Decision Tree  48594.141547  61444.631799  40772.481492\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# -----------------------------\n",
        "# Argument parser\n",
        "# -----------------------------\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--data\", type=str, required=True)\n",
        "parser.add_argument(\"--test_size\", type=float, default=0.2)\n",
        "parser.add_argument(\"--alpha\", type=float, default=1.0)\n",
        "\n",
        "# Pass arguments explicitly when running in a notebook\n",
        "args = parser.parse_args([\"--data\", \"/content/housing.csv\"])\n",
        "\n",
        "# -----------------------------\n",
        "# Load data\n",
        "# -----------------------------\n",
        "df = pd.read_csv(args.data)\n",
        "\n",
        "# -----------------------------\n",
        "# Handle missing values\n",
        "# -----------------------------\n",
        "df[\"total_bedrooms\"] = df[\"total_bedrooms\"].fillna(df[\"total_bedrooms\"].median())\n",
        "\n",
        "# -----------------------------\n",
        "# Encode categorical variable\n",
        "# -----------------------------\n",
        "df = pd.get_dummies(df, columns=[\"ocean_proximity\"], drop_first=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Split features & target\n",
        "# -----------------------------\n",
        "X = df.drop(\"median_house_value\", axis=1)\n",
        "y = df[\"median_house_value\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=args.test_size, random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Feature Scaling\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# -----------------------------\n",
        "# Models\n",
        "# -----------------------------\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Ridge Regression\": Ridge(alpha=args.alpha),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(max_depth=10, random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "# -----------------------------\n",
        "# Train & Evaluate\n",
        "# -----------------------------\n",
        "for name, model in models.items():\n",
        "    if name == \"Decision Tree\":\n",
        "        model.fit(X_train, y_train)\n",
        "        train_pred = model.predict(X_train)\n",
        "        test_pred = model.predict(X_test)\n",
        "    else:\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        train_pred = model.predict(X_train_scaled)\n",
        "        test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    rmse_train = np.sqrt(mean_squared_error(y_train, train_pred))\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "    mae_test = mean_absolute_error(y_test, test_pred)\n",
        "\n",
        "    results.append([name, rmse_train, rmse_test, mae_test])\n",
        "\n",
        "# -----------------------------\n",
        "# Results table\n",
        "# -----------------------------\n",
        "results_df = pd.DataFrame(\n",
        "    results,\n",
        "    columns=[\"Model\", \"RMSE (Train)\", \"RMSE (Test)\", \"MAE (Test)\"]\n",
        ")\n",
        "\n",
        "print(\"\\nModel Comparison:\\n\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A comparison table for at least 3 models, such as:\n",
        "Linear Regression (baseline)\n",
        "Ridge/Lasso Regression\n",
        "Decision Tree Regressor (or Random Forest as extension) :"
      ],
      "metadata": {
        "id": "QmZWgghrXDlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model                       | RMSE (Train) | RMSE (Test) | MAE (Test) | Observation                 |\n",
        "| --------------------------- | ------------ | ----------- | ---------- | --------------------------- |\n",
        "| **Linear Regression**       | High         | High        | High       | Underfitting (High Bias)    |\n",
        "| **Ridge Regression**        | Medium       | Medium      | Medium     | Better generalization       |\n",
        "| **Decision Tree Regressor** | Very Low     | High        | High       | Overfitting (High Variance) |\n"
      ],
      "metadata": {
        "id": "gpWA_y1dXAUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Underfitting vs Overfitting Explanation\n",
        "\n",
        "Underfitting is observed in Linear Regression, where both training and testing errors are high. This happens because the model is too simple to capture the complex, non-linear relationship between housing features and prices, resulting in high bias.\n",
        "Ridge Regression improves performance by adding regularization, which reduces model complexity and improves generalization on unseen data.\n",
        "Overfitting is clearly seen in the Decision Tree Regressor, where training error is very low but testing error is high. This indicates that the model learns noise and specific patterns from the training data, leading to high variance.\n",
        "Thus, Ridge Regression provides the best balance between bias and variance in this problem."
      ],
      "metadata": {
        "id": "6RiRnqxuXRA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-linearity & Outliers:\n",
        "House prices are influenced by complex, non-linear factors such as location desirability, nearby infrastructure, and economic conditions. Linear models fail to capture this complexity, while decision trees may overreact to outliers, leading to unstable predictions. This highlights the need for regularization or ensemble models in real-world regression tasks."
      ],
      "metadata": {
        "id": "WTMBkIuAXdmP"
      }
    }
  ]
}